{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models for Ensemble Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression as lin\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import callbacks\n",
    "from keras.models import load_model\n",
    "\n",
    "from datetime import date\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data succesfully imported. Shape of X = (159, 687), y = (159, 5)\n"
     ]
    }
   ],
   "source": [
    "# Your directory\n",
    "os.chdir(\"/Users/benjaminlian/Documents/School/5th_year/Spring_2021/Master_Thesis\")\n",
    "\n",
    "# Define periodic prediction function\n",
    "def periods_lags(df, y_variable, n_periods, n_lags, frequency):\n",
    "    # Copy input data\n",
    "    df_copy = df.copy()\n",
    "    y = df_copy.loc[:, y_variable]\n",
    "    name_ = y.name\n",
    "    y_out = pd.DataFrame()\n",
    "    \n",
    "    # Drop y-variable from dataframe\n",
    "    df_copy.drop(columns = [y_variable], inplace = True)\n",
    "    \n",
    "    # Create periodic y-variables\n",
    "    for period in range(n_periods + 1):\n",
    "        name = name_ + \"_q_\" + str(period)\n",
    "        add_period = y.pct_change(period + 1)\n",
    "        add_period = add_period.shift(-period)\n",
    "        y_out = pd.concat([y_out, add_period.rename(name)], axis = 1)\n",
    "    \n",
    "    # Create lags of y-variables\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        name = name_ + \"_for_pred_lag_\" + str(lag)\n",
    "        add_lag = y.pct_change().replace(np.nan, 0)\n",
    "        add_lag.drop(index = add_lag.index[0], inplace = True)\n",
    "        add_lag = add_lag.shift(lag)\n",
    "        df_copy[name] = add_lag\n",
    "        \n",
    "    # Make sure X and y are of equal index\n",
    "    y_out.replace(to_replace = np.nan, value = 0, inplace = True)\n",
    "    index = list(set(df_copy.dropna().index) & set(y_out.index))\n",
    "    X = df_copy.loc[index, :]\n",
    "    y = y_out.loc[index, :]\n",
    "    X.sort_index(inplace = True)\n",
    "    y.sort_index(inplace = True)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# User inputs\n",
    "n_periods = 4\n",
    "n_lags = 1\n",
    "frequency = 1\n",
    "\n",
    "# Import data and publication dates\n",
    "df = pd.read_excel(\"Data/master_thesis_data.xlsx\", index_col = 0)\n",
    "\n",
    "# Extract NO_folio_publication_date\n",
    "pub_dates = df.NO_folio_publication_date\n",
    "\n",
    "df, folio_rate = periods_lags(df, \"NO_folio_publication_date\", n_periods, n_lags, frequency)\n",
    "folio_rate.rename(columns = {\"NO_folio_publication_date\":\"NO_folio_rate\"}, inplace = True)\n",
    "                \n",
    "print(\"Data succesfully imported. Shape of X = {}, y = {}\".format(df.shape, folio_rate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (55, 687)\n",
      "X test: (104, 687)\n",
      "y train: (55, 5)\n",
      "y test: (104, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = tts(df, folio_rate, test_size = 0.65, shuffle = False, random_state = None)\n",
    "\n",
    "# === Standardization ===\n",
    "# Extract indeces and columns from data\n",
    "X_train_index = X_train.index\n",
    "X_test_index = X_test.index\n",
    "y_train_index = y_train.index\n",
    "y_test_index = y_test.index\n",
    "X_columns = X_train.columns\n",
    "y_columns = y_train.columns\n",
    "\n",
    "# y-variables to arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print shapes\n",
    "print(\"X train: {}\".format(X_train.shape))\n",
    "print(\"X test: {}\".format(X_test.shape))\n",
    "print(\"y train: {}\".format(y_train.shape))\n",
    "print(\"y test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions for base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === !IMPORTANT! ===\n",
    "    # In order to get similar results for each compiling, this segment of code needs to be compiled first every time.\n",
    "# Set seed for keras models\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "seed_num = 2\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed_num)\n",
    "rn.seed(seed_num)\n",
    "tf.random.set_seed(seed_num)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Set seed for random forest algos\n",
    "np.random.seed(2)\n",
    "\n",
    "def prediction_outputs(model, X_train, X_test):\n",
    "    train = X_train.copy()\n",
    "    test = X_test.copy()\n",
    "    gap = len(X_train_index) - len(X_train)\n",
    "    is_predictions = pd.Series(model.predict(train).reshape(-1), index = X_train_index[gap:])\n",
    "    oos_predictions = pd.Series(model.predict(test).reshape(-1), index = X_test_index[gap:])\n",
    "    \n",
    "    return is_predictions, oos_predictions\n",
    "\n",
    "def elastic_net(X_train, y_train, X_test, y_test):\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Define alphas and lambdas for grid search\n",
    "    alphas = np.arange(0, 1, 0.1)\n",
    "    lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    "    # Cross validations\n",
    "    tscv = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "    # Instantiate model\n",
    "    model_tscv = ElasticNetCV(l1_ratio = alphas,\n",
    "                            alphas = lambdas,\n",
    "                            cv = tscv,\n",
    "                            n_jobs = -1,\n",
    "                            verbose = 0\n",
    "                            )\n",
    "\n",
    "    # Fit model\n",
    "    model_tscv.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model_tscv, X_train, X_test)\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    return model_tscv, is_pred, oos_pred, y_train, y_test \n",
    "    \n",
    "def linear_regression(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = lin()\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def k_nearest(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = KNeighborsRegressor()\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def decision_tree(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = DecisionTreeRegressor(random_state = 0)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def ada_booster(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = AdaBoostRegressor(random_state = 0)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def bagging_regressor(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = BaggingRegressor(random_state = 0)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = RandomForestRegressor(random_state = 0)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def extra_trees(X_train, y_train, X_test, y_test):\n",
    "    # Instantiate model\n",
    "    model = ExtraTreesRegressor(random_state = 0)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def neural_network(X_train, y_train, X_test, y_test):\n",
    "    # Inputs\n",
    "    units = 250\n",
    "    act = \"selu\"\n",
    "    dr = 0.5\n",
    "    batch_size = 256\n",
    "    epochs = 500\n",
    "\n",
    "    # Construction\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units = units, activation = act, input_shape = [X_train.shape[1]]),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(rate = dr),\n",
    "        layers.Dense(units = units, activation = act),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(rate = dr),\n",
    "        layers.Dense(units = units, activation = act),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(rate = dr),\n",
    "        layers.Dense(units = 1, activation = \"linear\")\n",
    "    ])\n",
    "\n",
    "    # Define the loss function and optimizer algorithm\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"mse\"\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        min_delta = 0.001, \n",
    "        patience = 20, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data = (X_test, y_test),\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        callbacks = [early_stopping],\n",
    "        verbose = 0\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(model, X_train, X_test)\n",
    "    \n",
    "    return model, is_pred, oos_pred, y_train, y_test\n",
    "\n",
    "def convolutional_neural_network(X_train, y_train, X_test, y_test):\n",
    "    def single_splitter(x_train, y_train, timesteps):\n",
    "        x, y = list(), list()\n",
    "        for i in range(len(x_train)):\n",
    "\n",
    "            end_ix = i + timesteps\n",
    "\n",
    "            if end_ix > len(x_train)-1:\n",
    "                break\n",
    "\n",
    "            seq_x = x_train[i:end_ix]\n",
    "            seq_y = y_train[end_ix]\n",
    "            x.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    ts = 5\n",
    "    x_cnn_train, y_cnn_train = single_splitter(X_train, y_train, timesteps = ts)\n",
    "    x_cnn_test, y_cnn_test = single_splitter(X_test, y_test, timesteps = ts)\n",
    "\n",
    "    cnn = keras.models.Sequential()\n",
    "    cnn.add(keras.layers.Conv1D(filters=75, kernel_size=4, activation='relu', input_shape=(x_cnn_train.shape[1], x_cnn_train.shape[2])))\n",
    "    cnn.add(keras.layers.MaxPool1D(pool_size=10, padding='same'))\n",
    "    #cnn.add(keras.layers.Conv1D(filters=100, kernel_size=2, activation='tanh'))\n",
    "    #cnn.add(keras.layers.MaxPool1D(pool_size=2, padding='same'))\n",
    "    cnn.add(keras.layers.Flatten())\n",
    "    cnn.add(keras.layers.Dropout(rate=0.8))\n",
    "    cnn.add(keras.layers.Dense(500, activation='relu'))\n",
    "    cnn.add(keras.layers.Dense(1, activation='linear'))\n",
    "    cnn.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Fit model:\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00005, patience = 20, restore_best_weights=True)\n",
    "\n",
    "    history = cnn.fit(x_cnn_train,\n",
    "                        y_cnn_train,\n",
    "                        batch_size=500,\n",
    "                        epochs=1000,\n",
    "                        callbacks=[early_stopping],\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0)\n",
    "\n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(cnn, x_cnn_train, x_cnn_test)\n",
    "    \n",
    "    return cnn, is_pred, oos_pred, y_cnn_train, y_cnn_test\n",
    "\n",
    "def lstm(X_train, y_train, X_test, y_test):\n",
    "    # Data split and reshape\n",
    "    X_train_array = np.asarray(X_train).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    y_train_array = np.asarray(y_train)\n",
    "    X_test_array = np.asarray(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    y_test_array = np.asarray(y_test)\n",
    "\n",
    "    # Construction\n",
    "    lstm = keras.Sequential([\n",
    "        layers.LSTM(50, input_shape = (X_train_array.shape[1], X_train_array.shape[2])),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Define the loss function and optimizer algorithm\n",
    "    lstm.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"mse\"\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        min_delta = 0.001, \n",
    "        patience = 20, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    lstm.fit(X_train_array, y_train_array, \n",
    "                        epochs = 50, \n",
    "                        batch_size = 500,\n",
    "                        callbacks = [early_stopping], \n",
    "                        validation_data = (X_test_array, y_test_array), \n",
    "                        verbose = 0, \n",
    "                        shuffle = False);\n",
    "\n",
    "    # Predictions\n",
    "    is_pred, oos_pred = prediction_outputs(lstm, X_train_array, X_test_array)\n",
    "    \n",
    "    return lstm, is_pred, oos_pred, y_train_array, y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time of fitting all base models for t = 0: 9 (9)\n",
      "Total time of fitting all base models for t = 1: 9 (18)\n",
      "Total time of fitting all base models for t = 2: 9 (27)\n",
      "Total time of fitting all base models for t = 3: 10 (37)\n",
      "Total time of fitting all base models for t = 4: 9 (46)\n"
     ]
    }
   ],
   "source": [
    "base_models = {\"linear_regression\":linear_regression,\n",
    "               \"elastic_net\":elastic_net,\n",
    "               \"k_nearest_neighbors\":k_nearest,\n",
    "               \"decision_tree_regressor\":decision_tree,\n",
    "               \"ada_boost_regressor\":ada_booster,\n",
    "               \"bagging_regressor\":bagging_regressor,\n",
    "               \"random_forest\":random_forest,\n",
    "               \"extra_trees\":extra_trees,\n",
    "               \"neural_network\":neural_network,\n",
    "               \"convolutional_neural_network\":convolutional_neural_network,\n",
    "               \"lstm\":lstm}\n",
    "\n",
    "fitted_models, is_pred_dict, oos_pred_dict = {}, {}, {}\n",
    "\n",
    "z_ = [0]\n",
    "for period in range(y_train.shape[1]):\n",
    "    total_time = list()\n",
    "    is_predictions = pd.DataFrame()\n",
    "    oos_predictions = pd.DataFrame()\n",
    "    for model in base_models:\n",
    "        start = dt.datetime.now()\n",
    "        model_from_dict = base_models[model]\n",
    "        mdl, is_pred, oos_pred, y_train_, y_test_ = model_from_dict(X_train, y_train[:, period], X_test, y_test[:, period])\n",
    "        end = dt.datetime.now()\n",
    "        diff = (end - start).total_seconds()\n",
    "        total_time.append(diff)\n",
    "        #print(\"{} fitted. Completed in {} seconds\".format(model, round(diff, 2)))\n",
    "        fitted_models[model + \"_{}\".format(period)] = mdl\n",
    "        is_predictions = pd.concat([is_predictions, is_pred.rename(model)], axis = 1)\n",
    "        oos_predictions = pd.concat([oos_predictions, oos_pred.rename(model)], axis = 1)\n",
    "    \n",
    "    is_pred_dict[\"is_pred_{}\".format(period)] = is_predictions\n",
    "    oos_pred_dict[\"oos_pred_{}\".format(period)] = oos_predictions\n",
    "\n",
    "    x = period\n",
    "    y = round(sum(total_time))\n",
    "    z_.append(y)\n",
    "    z = sum(z_)\n",
    "    print(\"Total time of fitting all base models for t = {}: {} ({})\".format(x, y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if frequency == 0:\n",
    "    freq = \"daily\"\n",
    "elif frequency == 1:\n",
    "    freq = \"pdates\"\n",
    "\n",
    "for period in range(y_test.shape[1]):\n",
    "    export = oos_pred_dict[\"oos_pred_{}\".format(period)].dropna()\n",
    "    export.to_excel(os.getcwd() + \"/Data/base_models_pred_{}_{}.xlsx\".format(freq, period))\n",
    "\n",
    "pub_dates.to_excel(os.getcwd() + \"/Data/base_models_predictions_{}.xlsx\".format(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
