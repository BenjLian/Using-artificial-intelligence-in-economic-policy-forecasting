{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging, cleaning, and lagging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs\n",
    "Use defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start date for data slicing, default = 2000-01-01:  \n",
      "End date for data slicing, default = 2020-12-31:  \n",
      "Number of lags for daily data, default = 5:  \n",
      "Variables to drop, default =  chinaHK_CPI and STYRINGSRENTEN:  \n",
      "Data frequency. 0 = daily, 1 = by publication, default = 1:  \n"
     ]
    }
   ],
   "source": [
    "def try_(input_, default = []):\n",
    "    if not input_:\n",
    "        return default\n",
    "    return input_\n",
    "\n",
    "# Start date\n",
    "start = input(\"Start date for data slicing, default = 2000-01-01: \")\n",
    "start = try_(start, \"2000-01-01\")\n",
    "\n",
    "# End date\n",
    "end = input(\"End date for data slicing, default = 2020-12-31: \")\n",
    "end = try_(end, \"2020-12-31\")\n",
    "\n",
    "# Number of lags\n",
    "n_lags = input(\"Number of lags for daily data, default = 5: \")\n",
    "if n_lags == \"\":\n",
    "    pass\n",
    "else:\n",
    "    n_lags = int(n_lags)\n",
    "n_lags = try_(n_lags, 5)\n",
    "\n",
    "# Variables to drop\n",
    "drop_variables = input(\"Variables to drop, default =  chinaHK_CPI and STYRINGSRENTEN: \").split()\n",
    "drop_variables = try_(drop_variables, \"chinaHK_CPI STYRINGSRENTEN\")\n",
    "    \n",
    "# Frequency\n",
    "frequency = input(\"Data frequency. 0 = daily, 1 = by publication, default = 1: \")\n",
    "if frequency == \"\":\n",
    "    pass\n",
    "else:\n",
    "    frequency = int(frequency)\n",
    "frequency = try_(frequency, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data ===\n",
    "# Read the whole excel file top_data\n",
    "os.chdir(\"/Users/benjaminlian/Documents/School/5th_year/Spring_2021/Master_Thesis\")\n",
    "xls = pd.ExcelFile(\"Data/top_data_3.xlsx\")\n",
    "\n",
    "# Construct the seperate dataframes and get all column names\n",
    "dic = {}\n",
    "col_names = []\n",
    "sheets = xls.sheet_names\n",
    "sheets.remove(\"Innhold\")\n",
    "\n",
    "for i in range(len(sheets)):\n",
    "    dic[sheets[i]] = pd.read_excel(xls, sheets[i], index_col = 0)\n",
    "    col_names += list(dic[sheets[i]].columns)\n",
    "\n",
    "# Construct empty dataframe with full timeline\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "datelist = pd.date_range(start = dt.datetime(1990, 1, 1), end = dt.datetime(2021, 1, 15)).tolist()\n",
    "datelist = pd.DataFrame(np.zeros(len(datelist)), index = datelist)\n",
    "\n",
    "# Create dataframe of Forklaringsvariabler_5 formatting and lags\n",
    "lags = dic[\"Forklaringsvariabler\"].loc[:, [\"Variablenavn\", \"Publiseringslag\"]].reset_index(drop = True)\n",
    "lags.dropna(inplace = True)\n",
    "freq = dic[\"Forklaringsvariabler\"].loc[:, [\"Variablenavn\", \"Frekvens\"]].reset_index(drop = True)\n",
    "freq.dropna(inplace = True)\n",
    "\n",
    "# Create series for NO_folio_publication_dates\n",
    "pub_dates = dic[\"Sheet22\"].sort_index() / 100\n",
    "\n",
    "# Remove sheets from the top_data dictionary\n",
    "del dic[\"Forklaringsvariabler\"]\n",
    "sheets.remove(\"Forklaringsvariabler\")\n",
    "del dic[\"Sheet22\"]\n",
    "sheets.remove(\"Sheet22\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_return(vector, frequency):\n",
    "    if frequency == \"d\":\n",
    "        pr_dict = dict()\n",
    "        pr_dict[vector.name + \"_d_2_d\"]  = vector.pct_change(1)\n",
    "        pr_dict[vector.name + \"_d_2_w\"]  = vector.pct_change(5)\n",
    "        pr_dict[vector.name + \"_d_2_2w\"] = vector.pct_change(10)\n",
    "        pr_dict[vector.name + \"_d_2_m\"]  = vector.pct_change(30)\n",
    "        pr_dict[vector.name + \"_d_2_2m\"] = vector.pct_change(60)\n",
    "        pr_dict[vector.name + \"_d_2_k\"]  = vector.pct_change(90)\n",
    "        pr_dict[vector.name + \"_d_2_2k\"] = vector.pct_change(183)\n",
    "        pr_dict[vector.name + \"_d_2_y\"]  = vector.pct_change(365)\n",
    "        \n",
    "        for n in range(n_lags):\n",
    "            pr_dict[vector.name + \"_d_2_d_lag{}\".format(n + 1)] = pr_dict[vector.name + \"_d_2_d\"].shift(n + 1)\n",
    "    \n",
    "    elif frequency == \"u\":\n",
    "        pr_dict = dict()\n",
    "        pr_dict[vector.name + \"_w_2_w\"]  = vector.pct_change(1)\n",
    "        pr_dict[vector.name + \"_w_2_2w\"] = vector.pct_change(2)\n",
    "        pr_dict[vector.name + \"_w_2_m\"]  = vector.pct_change(4)\n",
    "        pr_dict[vector.name + \"_w_2_2m\"] = vector.pct_change(9)\n",
    "        pr_dict[vector.name + \"_w_2_k\"]  = vector.pct_change(13)\n",
    "        pr_dict[vector.name + \"_w_2_2k\"] = vector.pct_change(26)\n",
    "        pr_dict[vector.name + \"_w_2_y\"]  = vector.pct_change(52)\n",
    "    \n",
    "    elif frequency == \"m\":\n",
    "        pr_dict = dict()\n",
    "        pr_dict[vector.name + \"_m_2_m\"]  = vector.pct_change(1)\n",
    "        pr_dict[vector.name + \"_m_2_2m\"] = vector.pct_change(2)\n",
    "        pr_dict[vector.name + \"_m_2_k\"]  = vector.pct_change(3)\n",
    "        pr_dict[vector.name + \"_m_2_2k\"] = vector.pct_change(6)\n",
    "        pr_dict[vector.name + \"_m_2_y\"]  = vector.pct_change(12)\n",
    "    \n",
    "    elif frequency == \"k\":\n",
    "        pr_dict = dict()\n",
    "        pr_dict[vector.name + \"_k_2_k\"]  = vector.pct_change(1)\n",
    "        pr_dict[vector.name + \"_q_2_2k\"] = vector.pct_change(2)\n",
    "        pr_dict[vector.name + \"_q_2_y\"]  = vector.pct_change(4)\n",
    "    \n",
    "    elif frequency == \"å\":\n",
    "        pr_dict = dict()\n",
    "        pr_dict[vector.name + \"_å_2_å\"]  = vector.pct_change(1)\n",
    "\n",
    "    return pr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables deleted:\n",
      "ECB_QE_å_2_å\n",
      "oil_inv_k_2_k\n",
      "oil_inv_q_2_2k\n",
      "oil_inv_q_2_y\n",
      "EUR_NOK_d_2_y\n",
      "NO_EL_price_k_2_k\n",
      "NO_EL_price_q_2_2k\n",
      "NO_EL_price_q_2_y\n",
      "NO_KPI_JA_m_2_m\n",
      "NO_KPI_JA_m_2_2m\n",
      "NO_KPI_JA_m_2_k\n",
      "NO_KPI_JA_m_2_2k\n",
      "NO_KPI_JA_m_2_y\n",
      "NO_KPI_JAE_m_2_m\n",
      "NO_KPI_JAE_m_2_2m\n",
      "NO_KPI_JAE_m_2_k\n",
      "NO_KPI_JAE_m_2_2k\n",
      "NO_KPI_JAE_m_2_y\n",
      "sweden_folio_rate_m_2_m\n",
      "sweden_folio_rate_m_2_2m\n",
      "sweden_folio_rate_m_2_k\n",
      "sweden_folio_rate_m_2_2k\n",
      "sweden_folio_rate_m_2_y\n",
      "interest_rates_on_loans_m_2_m\n",
      "interest_rates_on_loans_m_2_2m\n",
      "interest_rates_on_loans_m_2_k\n",
      "interest_rates_on_loans_m_2_2k\n",
      "interest_rates_on_loans_m_2_y\n",
      "FED_QE_k_2_k\n",
      "FED_QE_q_2_2k\n",
      "FED_QE_q_2_y\n",
      "fish_pool_NOK_w_2_w\n",
      "fish_pool_NOK_w_2_2w\n",
      "fish_pool_NOK_w_2_m\n",
      "fish_pool_NOK_w_2_2m\n",
      "fish_pool_NOK_w_2_k\n",
      "fish_pool_NOK_w_2_2k\n",
      "fish_pool_NOK_w_2_y\n"
     ]
    }
   ],
   "source": [
    "# === Formatting ===\n",
    "# Periodic returns\n",
    "dic_2 = dict()\n",
    "for sheet in dic:\n",
    "    dic_vars = dict()\n",
    "    for variable in dic[sheet]:\n",
    "        if variable in drop_variables:\n",
    "            pass\n",
    "        else:\n",
    "            series = dic[sheet].loc[:, variable]\n",
    "            frequency_ = freq.loc[freq.loc[:, \"Variablenavn\"] == variable, :].Frekvens.item()\n",
    "            if series.index[0] > series.index[1]:\n",
    "                series = series.sort_index()\n",
    "            dict_vectors = period_return(series, frequency_)\n",
    "            for key in dict_vectors:\n",
    "                if np.isinf(dict_vectors[key]).any():\n",
    "                    dict_vectors[key].replace([np.inf, -np.inf], 0, inplace = True)\n",
    "            dic_vars[variable] = pd.DataFrame(dict_vectors)\n",
    "    \n",
    "    df_ = pd.DataFrame()\n",
    "    for key in dic_vars:\n",
    "        _ = dic_vars[key]\n",
    "        df_ = pd.concat([df_, _], axis = 1)\n",
    "    dic_2[sheet] = df_\n",
    "\n",
    "# Concatenate sheets with full timeline dataframe\n",
    "df_full = datelist\n",
    "\n",
    "for sheet in dic_2:\n",
    "    df_full = pd.concat([dic_2[sheet], df_full], axis = 1, join = \"outer\")\n",
    "\n",
    "# Drop specified variables\n",
    "df_full.drop(columns = [0], inplace = True)\n",
    "    \n",
    "# === Lag variables (publication lags), drop specified variables and fill missing values ===\n",
    "df_copy = df_full.copy()\n",
    "for idx, lag in enumerate(lags.Publiseringslag):\n",
    "    if lags.Variablenavn.iloc[idx] in df_copy.columns:\n",
    "        variables = [column for column in df_copy.columns if lags.iloc[idx, 0] in column]\n",
    "        if lags.iloc[idx, 0] in drop_variables:\n",
    "            df_copy[:, variables] = []\n",
    "        df_copy.loc[:, variables] = df_copy.loc[:, variables].shift(periods = lag, freq = \"D\")\n",
    "\n",
    "# Fill missing\n",
    "df_copy.dropna(how = \"all\", inplace = True)\n",
    "df_filled = df_copy.ffill()\n",
    "\n",
    "# === Cut the dataframe ===\n",
    "# Define function that slices and drops variables given a period\n",
    "def wrangler(df, start, end):\n",
    "    print(\"Variables deleted:\")\n",
    "    df_ = df.copy()\n",
    "    sliced_df_dict = {}\n",
    "    for i in df_.columns:\n",
    "        if df_.loc[start:end, i].isna().any():\n",
    "            print(i)\n",
    "        else:\n",
    "            sliced_df_dict[i] = df_.loc[start:end, i]\n",
    "    \n",
    "    sliced_df = pd.concat(sliced_df_dict, axis = 1)\n",
    "    \n",
    "    return sliced_df\n",
    "\n",
    "# Slice\n",
    "# Note: Vil ha med NO_folio_publication_dates med nan i mellom publiseringer\n",
    "sliced_data = wrangler(df_filled, start, end)\n",
    "\n",
    "# === Merge with publication dates ===\n",
    "if frequency == 1:\n",
    "    sliced_data = pd.merge(pub_dates, sliced_data, left_index = True, right_index = True)\n",
    "else:\n",
    "    temp = pd.DataFrame(np.full([len(df_filled), 1], np.nan), index = df_filled.index)\n",
    "    temp = temp.join(pub_dates, how = \"outer\")\n",
    "    temp.NO_folio_publication_date.ffill(inplace = True)\n",
    "    temp.rename(columns = {\"NO_folio_publication_date\":\"NO_folio_rate\"}, inplace = True)\n",
    "    temp.drop(columns = [0], inplace = True)\n",
    "    sliced_data = pd.concat([sliced_data, pub_dates[start:end], temp[start:end]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "sliced_data.to_excel(\"./Data/master_thesis_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
